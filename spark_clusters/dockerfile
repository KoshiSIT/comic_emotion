FROM openjdk:11-jre-slim

# Install dependencies
RUN apt-get update && apt-get install -y python3 python3-pip wget curl

# Download and install Spark
RUN wget https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz && \
    tar -xvf spark-3.1.2-bin-hadoop3.2.tgz -C /opt/ && \
    rm spark-3.1.2-bin-hadoop3.2.tgz && \
    mv /opt/spark-3.1.2-bin-hadoop3.2 /opt/spark

# Set environment variables
ENV SPARK_HOME=/opt/spark
ENV PATH=$SPARK_HOME/bin:$PATH

# Install Python packages
RUN pip3 install pyspark==3.1.2 py4j==0.10.9 pymongo[srv] pandas numpy scipy


WORKDIR /opt/spark/work-dir
COPY app /app

CMD ["tail", "-f", "/dev/null"]